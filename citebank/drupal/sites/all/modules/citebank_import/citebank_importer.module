<?php
// $Id: citebank_importer.module,v 1.0.0.0 2010/09/15 4:44:44 dlheskett $

/** citebank_importer.module
 *
 * Copyright (c) 2010 Missouri Botanical Garden 
 *
 * @author: David L. Heskett (contractor: Adaptive Solutions Group)
 * @date Created: 10/01/2010
 *
 */

//define('DOS_MODE', true);
define('DOS_MODE', false);

define('IMPORT_DIR_PATH_FILES', '/sites/default/files/');


$includePath = dirname(__FILE__) . '/';

require_once($includePath . 'CiteBankBiblio.php');
require_once($includePath . 'ExcelTextImporter.php');
require_once($includePath . 'CSVHandler.php');
require_once($includePath . 'ReviewContent.php');
require_once($includePath . 'ImportUndoHandler.php');
require_once($includePath . 'SolrHandler.php');

/**
 * citebank_importer_view - 
 */
function citebank_importer_view(&$node, $teaser = FALSE, $page = FALSE)
{
	//echo 'here i am';
}

/**
 * citebank_importer_cron - 
 */
function citebank_importer_cron(&$node = null, $teaser = FALSE, $page = FALSE)
{
	// we need an off switch if processed that file.
	watchmen('Citebank importer cron');
	processCiteBankImport();
}

/**
 * citebank_importer_node_info - 
 */
function citebank_importer_node_info()
{
	return array(
		'citebank_importer' => array(
			'name'         => t('citebank_importer'),
			'module'       => 'citebank_importer',
			'description'  => t('Citebank Importer: Data import module for bringing in external data from various sources. Imports to Biblio records using a CSV file and the data files put in as attachments.'),
			'has_title'    => TRUE,
			'title_label'  => t('CiteBank Importer'),
			'has_body'     => FALSE
//			'' => '',
		)
	);
}



// ************************************************************
//  process import methods
// ************************************************************

/**
 *  processCiteBankImport - 
 */
function processCiteBankImport()
{
	$importFileName = '';
	$importer = new ExcelTextImporter();
	$biblios  = importProcess($importer, $importFileName);
	
	$solrHandler = new SolrHandler();
	
	// this probably is not the most ideal thing to do, 
	// we add any nodes that haven't been put into Solr but that ought to be there, just so happens they are not.
	// if Solr doesn't exist, which it will, safely handles either situation.
	// this will pick up nodes that for some reason may not get handled by their respective modules, such as OAI importing.
	// if we do not want this extra behavoir, comment out this line.  leave the touchSolr after the addCiteBankRecord though.
	$solrHandler->addNewNodesToSolr();

$msg = 'biblios count: [' . count($biblios) . ']';
watchmen($msg);
$msg = 'Total number of citations to process: [' . count($biblios) . ']';
watchmen($msg);
	
	// if no data, report error and get out
	if (count($biblios) == 0) {
		//watchmen('Citebank importer preview no data');
		return;
	}

	$x = new CiteBankBiblio();
	$importUndo = new ImportUndoHandler();
	
	$x->numExpectedCitations = count($biblios);  // note expected number of citations
	
	//$uid      = 242;
	$uid      = 0;
	
	$dirPath  = IMPORT_DIR_PATH_FILES;
	$linkPath = getLinkPath() . IMPORT_DIR_PATH_FILES;
	
	foreach ($biblios as $key => $biblio) {
		if (count($biblio) > 2) {
			
			// fill data
			$x->biblioNode->setDataByNodeXData($biblio);
			$biblioPlus = $x->biblioNode->processNode(null);
			
			// assign more data
//			if (@strlen($biblioPlus['biblio_remote_db_provider']) == 0) {
//				$x->biblioNode->data_source_org = 'CiteBank';
//				$x->biblioNode->data_source_prj = 'Import';
//				$x->biblioNode->data_source_url = 'Internal Import';
//			} else {
//				$x->biblioNode->data_source_org = $biblioPlus['biblio_remote_db_provider'];
//				$x->biblioNode->data_source_prj = $biblioPlus['biblio_label'];
//				$x->biblioNode->data_source_url = $biblioPlus['biblio_remote_db_name'];
//			}


			// assign source, org, url.  default to empty
			if (@strlen($biblioPlus['biblio_remote_db_provider']) == 0) {
				$x->biblioNode->data_source_org = '';
			} else {
				$x->biblioNode->data_source_org = $biblioPlus['biblio_remote_db_provider'];
			}

			if (@strlen($biblioPlus['biblio_label']) == 0) {
				$x->biblioNode->data_source_prj = '';
			} else {
				$x->biblioNode->data_source_prj = $biblioPlus['biblio_label'];
			}

			if (@strlen($biblioPlus['biblio_remote_db_name']) == 0) {
				$x->biblioNode->data_source_url = '';
			} else {
				$x->biblioNode->data_source_url = $biblioPlus['biblio_remote_db_name'];
			}

			$x->biblioNode->data_url = trim($biblioPlus['biblio_url'], '"');

			$x->biblioNode->filename = trim($biblioPlus['biblio_url'], '"');
			$x->biblioNode->dirPath  = $dirPath;
			$x->biblioNode->linkPath = $linkPath;
			
			/* 20110921 logic change */
			/* 
				1) if we have a local pdf file, we construct the biblio_url
				2) if we have 'http: or https:' in the data_url, that is an external link, and we do not do the work of adding the file as above requires
				3) if we have data_url as blank, then it is a citation only, we do not need to perform unique identifier checking, the biblio_url becomes the node link itself
				  item 3 here will not occur until sometime months later from now or longer.  when we create citation only capability.
				  citation only items may exist for items that have url links elsewhere but that are under copyright and we cannot link to them for legal reasons,
				  but at a future point may be allowed to, and then we can add the link, which will tie into our local Citebank PDF link and unique identifier system, to be
				  developed soon.
			*/
			
			$urlImportType = 1; // 1 = local file, 2 = http, 3 = blank and make citation only
			
			if (substr_count($x->biblioNode->data_url, 'http:') > 0) {
				$urlImportType = 2;
			} else if (substr_count($x->biblioNode->data_url, 'https:') > 0) {
				$urlImportType = 2;
			} else if (trim($x->biblioNode->data_url) == '') {
				$urlImportType = 3;
			} else {
				$urlImportType = 1;
			}
			
			// create the link path url  basically the filename combined with the host path
			// updates the biblio url
			// our source csv file, does not know a link path url, it only knows the actual filename, 
			//   which is buried in the csv under the "data_url" or 'biblio_url' associated field name
			// so, we hook our link path to the name of the data file
			// for an IA Internet Archive site, we will need to change the page link logic.
			switch ($urlImportType)
			{
				case 1:
					$x->biblioNode->data_url = $x->biblioNode->linkPath . $x->biblioNode->data_url;
					break;
				
				case 2:
					//$x->biblioNode->data_url = $x->biblioNode->data_url;
					// it is already a link we want
					break;
				
				case 3:
					$x->biblioNode->data_url = 'CitationONLY' . '_' . rand(9999,999999) . '_' . date('YmdHis'); // or something, TBD, until we fill in the node id
					break;
				
				default:
					break;
			}
			
			// make node array
			$biblioPlus = $x->biblioNode->processNode(null);
			$x->biblioNode->node = $biblioPlus;
			
			
			// view data
			$title = $biblioPlus['biblio_title'];
			//$filename = $biblioPlus['biblio_url'];
			$filename = trim($x->biblioNode->filename, '"');

			// fix the node.  we need to do this... why. 
			$x->biblioNode->node['biblio_url'] = $x->biblioNode->data_url;

			watchmen('CB import type ' . $urlImportType . ' [' . $x->biblioNode->data_url . ']');

//			echo '<br>' . "\n";
//			echo 'Title:[' . $title . ']' . '<br>' . "\n";
//			echo 'File:[' . $filename . '] ' . '<br>' . "\n";
//			echo '<br>' . "\n";
//			
//			// *******
//			echo 'url:[' . $x->biblioNode->node['biblio_url'] . '] ' . '<br>' . "\n";
//			echo 'url:[' . $x->biblioNode->data_url . '] ' . '<br>' . "\n";
//			echo '<br>' . "\n";
//	
//			//echo 'type:[' . $x->biblioNode->data_type . '] ' . '<br>' . "\n";
//			echo 'type:[' . $x->biblioNode->node['biblio_type'] . '] ' . '<br>' . "\n";
//			echo '<br>' . "\n";
	
			// ***** Write the record *****
			// check for a duplicate record
			$duplicate = false;
			if ($urlImportType != 3) {
				$duplicate = $x->checkDuplicate($x->biblioNode->data_url);
			}
			
			if (!$duplicate) {
				// write data
				//$node_save($x->biblioNode->node);
				
				$nid = 0;
				watchmen('to add ' . ' [' . $title . '] [' . $x->biblioNode->data_url . ']');
				
				$x->numCitationsItemsProcessed++;

				// log that item missing a title
				if (strlen(trim($title)) == 0) {
					$msg = 'no title for [' . $filename . '] ' . $title . '';
					watchmen($msg);
				}
				
				switch ($urlImportType)
				{
					case 1:  // file
						//watchmen('addCiteBankRecord ' . $nid . ' [' . $title . '] [' . $x->biblioNode->data_url . ']');
						$nid = $x->addCiteBankRecord($title, $filename, $x->biblioNode->node, $uid);
						watchmen('Record ' . $nid . ' [' . $title . '] [' . $x->biblioNode->data_url . ']');
						break;

					case 2:  // link
						//watchmen('addCiteBankRecordLink ' . $nid . ' [' . $title . '] [' . $x->biblioNode->data_url . ']');
						$nid = $x->addCiteBankRecordLink($title, $x->biblioNode->data_url, $x->biblioNode->node, $uid);  // citation using a web link instead of a file
						watchmen('Link ' . $nid . ' [' . $title . '] [' . $x->biblioNode->data_url . ']');
						break;

					case 3:  // citation only
						//watchmen('addCiteBankRecordCitation ' . $nid . ' [' . $title . '] [' . $x->biblioNode->data_url . ']');
						$nid = $x->addCiteBankRecordCitation($title, '', $x->biblioNode->node, $uid);  // citation ONLY, no link, no file
						watchmen('Citation ' . $nid . ' [' . $title . '] [' . $x->biblioNode->data_url . ']');
						break;
				}
				
				if ($nid) {
					$solrHandler->touchSolr($nid);
					$importUndo->makeUndoNid($nid, $importFileName);
					
					$x->numCitationsUploaded++;  // if it was given a nid, it should have been added
				}
				
				//echo '****[' . 'Write the record here' . ']****' . '<br>' . "\n";
			} else {
				//echo '****[' . 'Skip the duplicate record here' . ']****' . '<br>' . "\n";
				watchmen('duplicate file skipped: [' . $filename . '] [' . $x->biblioNode->data_url . ']');
			}
	
			//echo '****************************************';
			//echo '<br>' . "\n";
	
		}
	}
	
	// Report Final Results information
	// ******

	$msg = '' . $x;  // get string msg report
	watchmen($msg);


//	$expectedNumberOfCitations = $x->numExpectedCitations;
//	$msg = 'Number of Expected Citations: ' . $expectedNumberOfCitations;
//	watchmen($msg);
//	
//	$numCitationsUploaded = $x->numCitationsUploaded;
//	$msg = 'Number of Uploaded Citations: ' . $numCitationsUploaded;
//	watchmen($msg);
//	
//	$numCitationsItemsProcessed = $x->numCitationsItemsProcessed;
//	$msg = 'Count of Processed Citations: ' . $numCitationsItemsProcessed;
//	watchmen($msg);
//	
//	$numCitationsNoPdfs = $x->numCitationsNoPdfs;
//	$msg = 'Number of Not Found PDFs: ' . $numCitationsNoPdfs;
//	watchmen($msg);
//	
//	$listOfNoPdfs = $x->listCitationsNoPdfs;
//	foreach ($listOfNoPdfs as $keyList => $valList) {
//		;
//	}
}

/**
 *  importProcess - 
 */
function importProcess($n, &$importFileName)
{
	//$includePath = dirname(__FILE__) . '/';
	//
	//$fileName  = @($_REQUEST['file']    ? filter($_REQUEST['file'])    : $includePath . 'testJAMCADatabaseSG_small.csv');
	$fileName = '';
	$flagCleanup = false;
	
	// make a list of csv files, go through one, mark done, go through next later since running cron
	$x = new CSVHandler();
	$includePath = $x->includePath;
	$filenames = $x->findListImportFiles();
	
	if (count($filenames) > 0) {
		$file = $filenames[0];
		$fileName = $includePath . $file;

		// check if this is approved
		if ($x->isApproved($fileName)) {
			$flagCleanup = true;
		} else {
			// is preview?
			// yes
			if ($x->isPreviewed($fileName)) {
				//  done, exit
				watchmen('waiting for approval for: **[' . $file . ']**');
			// no
			} else {
				//  make preview tag file
				$x->makePreviewed($fileName);
				//  process and gen preview

				$contentFormat = BiblioNode::STRING_TO_CSV;
				//$contentFormat = BiblioNode::STRING_TO_STR;
				//$contentFormat = BiblioNode::STRING_TO_STRHTM;
				//$contentFormat = BiblioNode::STRING_TO_HTML;
				
				$reviewContent = new ReviewContent();
				$reviewContent->sourceFile = $fileName;
				$reviewContent->reviewerEmail = 'david.heskett@mobot.org';
				$msg = $reviewContent->createReviewContent($contentFormat);
				
				watchmen($msg);

				//  email it
				$reviewName = $reviewContent->shortFileName($fileName);
				$writeProofFile = $reviewContent->writeProof($fileName, $msg);
				$mailFlag = $reviewContent->sendProof($reviewName, $msg, $writeProofFile);

				if (!$mailFlag) {
					watchmen('did not send email out');
				}
				watchmen('preview processed, email it out for: **[' . $file . ']**' . '**[' . $fileName . ']**');
			}
			
			return;
		}
	} else {
		// no files
		return;
	}

	watchmen('import file to use: **[' . $fileName . ']**');
	$importFileName = shortFileName($fileName);
	
	$dataFile = '';
	if ($fileName) {
		
		$flagMSvsUx = DOS_MODE;

		$fileSep = ($flagMSvsUx ? '\\' : '/' );
		
		//$dataFile = '..' . $fileSep . $fileName;
		$dataFile = $fileName;
		
		if (file_exists($dataFile)) {
			//echo 'FileName:' . $dataFile . '<br>' . "\n";
			//echo '****************************************';
			//echo '<br>' . "\n";
		} else {
			//echo 'Error - filename not found: ' . $dataFile . '';
			watchmen('Error - filename not found: ' . $dataFile . '');
			return;
		}
	}

	$biblios = $n->processFileIntoBiblioData($dataFile);

	// perform clean up 
	if ($flagCleanup) {
		$x->pushOffList($fileName);
		watchmen('import file expire: **[' . $fileName . ']**');
		
		// clean out real old ones while we are at it
		$purgefilenames = $x->findFilesToPurge();
		$x->purgeList($purgefilenames);
	}
	
	return $biblios;
}

/**
 *  shortFileName - 
 */
function shortFileName($filename)
{
	$x = explode('/', $filename);
	
	$count = count($x);
	
	$file = $x[$count - 1];
	
	return $file;
}

/**
 *  filter - 
 */
function filter($data)
{
	$filtered = stripslashes($data);
	
	return $filtered;
}

/**
 *  getLinkPath - 
 */
function getLinkPath()
{
	$linkPath = '';
	
	$hostSiteUrl = getServerName(); //$_SERVER['SERVER_NAME'];
	
	$linkPath = 'http://' . $hostSiteUrl;
	
	return $linkPath;
}

/**
 * getServerName - build a correct file path to the data store for the given file name.
 */
function getServerName()
{
	$servername = @$_SERVER['SERVER_NAME'];

	if (!$servername) {
		$rootplus = docRootPath();
		
		// problem, $_SERVER['DOCUMENT_ROOT'];  is not available via command line call, we get an empty string.
		// remedy, below.
		// cleverness here:
		// all the code sitting under drupal resides in 'sites/all', so it's a good key to split on cleanly
		// so, we have something like:
		//  /var/www/test3.citebank.org/sites/all/more/dirs/here...
		// we want:
		//  /var/www/test3.citebank.org/
		// so drop everything after including 'sites/all....'
		//
		$parts = explode('sites/all', $rootplus);
		$root = $parts[0];

		$servername = str_replace('/var/www/', '', $root);
	}
	
	$servername = rtrim($servername, '/');

	return $servername;
}

/**
 * docRootPath - get us a path, we have some odd issue with our server not being set correctly, so attempt a remedy
 */
function docRootPath()
{
	$path1 = $_SERVER['DOCUMENT_ROOT'];
	$path2 = $_SERVER['PWD'];
	
	$path = ($path1 ? $path1 : $path2);
	
	return $path;
}

//watchdog($type, $message, $variables = array(), $severity = WATCHDOG_NOTICE, $link = NULL);
/**
 * watchmen - handy drupal watch logger, give it a msg and go
 */
function watchmen($msg, $watchFlag = true, $type = 'CiteBankImp', $addDate = true)
{
	static $reportLogger = null;
	
	if ($watchFlag) {
		if ($addDate) {
			$msg .= ' ' . date('YmdHis');
		}
		
		watchdog($type, $msg);  // drupal system call
		
		if ($reportLogger) {
			$reportLogger->writeReportMsg($msg);
		} else {
			$includePath = dirname(__FILE__) . '/';
			require_once($includePath . 'ReportLogger.php');

			$reportLogger = new ReportLogger();

			$reportLogger->writeReportMsg($msg);
		}
	}
}

// ************************************************************
// ************************************************************
